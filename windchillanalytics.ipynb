{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Windchill Apache Log Analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skf.util import connect_sql,update_data_multirow,update_data,disconnect_sql,process_apache_logs\n",
    "import os\n",
    "import json\n",
    "\n",
    "# property file configuration\n",
    "config = json.load(open('config.json'))\n",
    "log_path = 'C:\\\\temp\\\\WcProd_ApacheLogs\\\\accesslogs' #config.get('logs_path')\n",
    "sql = (\"INSERT INTO apachelog VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s);\")\n",
    "\n",
    "node_dir = os.listdir(log_path) # To identify which node apache logs processed\n",
    "logfile = ''\n",
    "\n",
    "# Connect database\n",
    "connection = connect_sql(config.get('db_host'), config.get('db_user'), config.get('db_password'), config.get('db_name'))\n",
    "\n",
    "for node in node_dir:\n",
    "    cur_log_path = log_path + os.sep + node\n",
    "    logs_path = os.listdir(cur_log_path)\n",
    "    for cur_logfile in logs_path:\n",
    "        logfile=cur_log_path + os.sep + cur_logfile\n",
    "        try:\n",
    "            # Process apache logs\n",
    "            logdata = process_apache_logs(logfile,node)\n",
    "            qtuple = [tuple(item) for item in logdata]\n",
    "\n",
    "            # Load data to datbase\n",
    "            try:\n",
    "                update_data_multirow(connection,sql,qtuple) # Commented to check logs files where error occurred\n",
    "            # try:\n",
    "            #     for log in qtuple:\n",
    "            #         query = (\"INSERT INTO apachelog VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s);\" % (tuple(log),))\n",
    "            #         print(query)\n",
    "            #         update_data(connection,query)\n",
    "            except Exception as ee:\n",
    "                print ('Error Occurred on inserting line '+ str(logfile))\n",
    "            os.rename(logfile,logfile.replace('accesslogs',f'processed'))\n",
    "        except Exception as e:\n",
    "            print ('Error Occurred for file '+logfile +' Exception: '+ e) # +' Exception: '+ e\n",
    "\n",
    "# Load data to datbase\n",
    "#     update_data(connection,query)\n",
    "\n",
    "# Read data from datbase\n",
    "# query = \"SELECT * FROM apachelog WHERE technology='odata';\"\n",
    "# rows= read_data(connection,query)\n",
    "# print(rows)\n",
    "\n",
    "# Disconnect Database\n",
    "disconnect_sql(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8392840\n",
      "16814573\n",
      "25317992\n"
     ]
    }
   ],
   "source": [
    "from skf.util import process_apache_logs\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# property file configuration\n",
    "config = json.load(open('config.json'))\n",
    "log_path = config.get('logs_path')\n",
    "\n",
    "node_dir = os.listdir(log_path) # To identify which node apache logs processed\n",
    "logdata = []\n",
    "\n",
    "for node in node_dir:\n",
    "    cur_log_path = log_path + os.sep + node\n",
    "    # Process apache logs\n",
    "    temp_logdata = process_apache_logs(cur_log_path,node)\n",
    "    logdata.extend(temp_logdata)\n",
    "    print(len(logdata))\n",
    "\n",
    "with open(f'{log_path}accesslog_022024.csv', 'w', encoding=\"utf-8\", newline='') as f:\n",
    "    # f.writelines(str(partsList))\n",
    "    writer = csv.writer(f)\n",
    "    for row in logdata:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from skf.util import connect_sql,update_data_multirow,disconnect_sql\n",
    "\n",
    "# property file configuration\n",
    "config = json.load(open('config.json'))\n",
    "query = (\"INSERT INTO apachelog VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s);\")\n",
    "\n",
    "# Connect database\n",
    "connection = connect_sql(config.get('db_host'), config.get('db_user'), config.get('db_password'), config.get('db_name'))\n",
    "\n",
    "with open('C:\\\\temp\\\\WcProd_ApacheLogs\\\\Feb\\\\accesslog_022024.csv', 'r') as f:\n",
    "    reader = list(csv.reader(f, delimiter=','))\n",
    "    qtuple = [tuple(item) for item in reader]\n",
    "    print(qtuple[1:4])\n",
    "    update_data_multirow(connection,query,qtuple)\n",
    "    #for row in reader:\n",
    "    #    print(row)\n",
    "\n",
    "disconnect_sql(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from skf.util import connect_sql,update_data_multirow,disconnect_sql\n",
    "\n",
    "# property file configuration\n",
    "config = json.load(open('config.json'))\n",
    "query = (\"INSERT INTO apachelog VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s);\")\n",
    "\n",
    "# Connect database\n",
    "connection = connect_sql(config.get('db_host'), config.get('db_user'), config.get('db_password'), config.get('db_name'))\n",
    "update_data_multirow(connection,query,qtuple)\n",
    "disconnect_sql(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "disconnect_sql(connection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
